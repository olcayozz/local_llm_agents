version: "3.8"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    networks:
      - front-tier

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - front-tier
  
  python:
    build:
      context: ./services/python
      dockerfile: python.Dockerfile
    image: llm/python:latest
    hostname: python
    domainname: python.com
    container_name: python
    ports:
      - "5000:5000"
    volumes:
      - python:/root/app
    networks:
      - front-tier
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
      
  python_dev:
    build:
      context: ./services/python_dev
      dockerfile: python_dev.Dockerfile
    image: llm/python_dev:latest
    hostname: python_dev
    domainname: python_dev.com
    container_name: python_dev
    volumes:
      - python_dev:/root/app
      - ./services/python_dev/app:/root/app
    networks:
      - front-tier
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
    
  agents:
    build:
      context: ./services/agents
      dockerfile: agents.Dockerfile
    image: llm/agents:latest
    hostname: agents
    domainname: agents.com
    container_name: agents
    volumes:
      - agents:/root/app
      - ./services/agents/app:/root/app
    networks:
      - front-tier
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: unless-stopped
  
  simple_agent:
    build:
      context: ./services/simple_agent
      dockerfile: simple_agent.Dockerfile
    image: llm/simple_agent:latest
    hostname: simple_agent
    domainname: simple_agent.com
    container_name: simple_agent
    volumes:
      #- simple_agent:/root/app
      - ./services/simple_agent/app:/root/app
    networks:
      - front-tier
      - back-tier
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OLLAMA_MODEL=hf.co/HuggingFaceTB/SmolLM2-360M-Instruct-GGUF:Q8_0
    depends_on:
      - ollama
      - qdrant
    restart: unless-stopped

  mcp_server:
    build:
      context: ./services/mcp_server
      dockerfile: mcp_server.Dockerfile
    image: llm/mcp_server:latest
    hostname: mcp_server
    domainname: mcp_server.com
    container_name: mcp_server
    volumes:
      - mcp_server:/root/app
    networks:
      - front-tier

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333"   # REST API
      - "6334:6334"   # gRPC API
    volumes:
      - qdrant_data:/qdrant/storage
    restart: unless-stopped
    networks:
      - back-tier

volumes:
  python:
  mcp_server:
  ollama_data:
  python_dev:
  simple_agent:
  agents:
  qdrant_data:


networks:
  front-tier:
  back-tier: